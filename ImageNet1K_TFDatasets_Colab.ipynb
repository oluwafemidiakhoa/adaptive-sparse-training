{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ImageNet-1K AST Training with TensorFlow Datasets\n",
        "\n",
        "**Developed by Oluwafemi Idiakhoa**\n",
        "\n",
        "**Advantage**: No need to download 150GB! Streams directly from TensorFlow.\n",
        "\n",
        "**Goal**: Validate AST on full ImageNet-1K (1.28M images)\n",
        "\n",
        "**Expected Results**:\n",
        "- Accuracy: 70-72%\n",
        "- Energy Savings: 80%\n",
        "- Training Time: ~5 hours on A100\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install TensorFlow Datasets and other dependencies\n",
        "!pip install -q tensorflow-datasets tensorflow torch torchvision tqdm matplotlib numpy\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Mount Google Drive for Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs(\"/content/drive/MyDrive/ast_imagenet1k_tfds_checkpoints\", exist_ok=True)\n",
        "print(\"‚úÖ Google Drive mounted - checkpoints will be saved here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load ImageNet-1K via TensorFlow Datasets\n",
        "\n",
        "This will stream the data without downloading 150GB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"üîÑ Loading ImageNet-1K metadata...\")\n",
        "print(\"Note: First run will download ~6GB of metadata, then streams during training\")\n",
        "print()\n",
        "\n",
        "# This prepares the dataset but doesn't download all images\n",
        "builder = tfds.builder('imagenet2012')\n",
        "builder.download_and_prepare()\n",
        "\n",
        "info = builder.info\n",
        "print(f\"‚úÖ ImageNet-1K ready!\")\n",
        "print(f\"   Training samples: {info.splits['train'].num_examples:,}\")\n",
        "print(f\"   Validation samples: {info.splits['validation'].num_examples:,}\")\n",
        "print(f\"   Number of classes: {info.features['label'].num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create PyTorch-Compatible DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class TFDSImageNetDataset(IterableDataset):\n",
        "    \"\"\"Convert TensorFlow Dataset to PyTorch IterableDataset\"\"\"\n",
        "    \n",
        "    def __init__(self, split, transform=None):\n",
        "        self.ds = tfds.load('imagenet2012', split=split, shuffle_files=True)\n",
        "        self.ds = self.ds.repeat()  # Repeat indefinitely\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for example in tfds.as_numpy(self.ds):\n",
        "            image = example['image']\n",
        "            label = example['label']\n",
        "            \n",
        "            # Convert to PIL Image\n",
        "            image = Image.fromarray(image)\n",
        "            \n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            yield image, label\n",
        "\n",
        "# Define transforms\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "    transforms.RandomErasing(p=0.25),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Transforms configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Clone AST Repository and Load Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/oluwafemidiakhoa/adaptive-sparse-training.git\n",
        "%cd adaptive-sparse-training\n",
        "\n",
        "from KAGGLE_IMAGENET1K_AST_CONFIGS import get_config\n",
        "\n",
        "# Get Ultra configuration\n",
        "config = get_config(\"ultra\")\n",
        "\n",
        "# Adjust for A100/V100\n",
        "config.batch_size = 256  # Adjust based on your GPU\n",
        "config.num_workers = 0   # TFDS handles threading internally\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ULTRA CONFIGURATION - ImageNet-1K via TensorFlow Datasets\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Classes: {config.num_classes}\")\n",
        "print(f\"Total Epochs: {config.num_epochs}\")\n",
        "print(f\"Batch Size: {config.batch_size}\")\n",
        "print(f\"Target Activation Rate: {config.target_activation_rate:.0%}\")\n",
        "print(f\"Expected Energy Savings: {(1-config.target_activation_rate)*100:.0f}%\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = TFDSImageNetDataset('train', transform=train_transform)\n",
        "val_dataset = TFDSImageNetDataset('validation', transform=val_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    num_workers=0,  # TFDS handles this\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ DataLoaders created\")\n",
        "print(\"üì¶ Streaming ImageNet-1K from TensorFlow Datasets\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Training Script\n",
        "\n",
        "**Note**: This uses the same AST implementation from ImageNet-100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The rest is identical to your ImageNet-1K training script\n",
        "# Just copy the training loop from ImageNet1K_Ultra_Colab.ipynb cell 16\n",
        "\n",
        "print(\"‚ö†Ô∏è  Copy the training script from your ImageNet1K_Ultra_Colab.ipynb\")\n",
        "print(\"    (The one starting with: import torch.nn as nn...)\")\n",
        "print()\n",
        "print(\"The only difference is we're using TFDS streaming instead of local files!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advantages of This Approach\n",
        "\n",
        "‚úÖ **No 150GB download** - Streams data as needed\n",
        "\n",
        "‚úÖ **Works immediately** - No waiting for dataset access\n",
        "\n",
        "‚úÖ **Same training code** - Just different data loading\n",
        "\n",
        "‚úÖ **Legitimate source** - Official TensorFlow Datasets\n",
        "\n",
        "‚ö†Ô∏è **Small downside**: First epoch may be slightly slower due to streaming"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
