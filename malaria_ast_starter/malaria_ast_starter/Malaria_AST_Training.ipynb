{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üåø Energy-Efficient Malaria Detection with Adaptive Sparse Training\n",
    "\n",
    "**Train a 95%+ accuracy malaria classifier with 60-90% energy savings!**\n",
    "\n",
    "This notebook demonstrates:\n",
    "- ‚ö° Adaptive Sparse Training (AST) with Sundew algorithm\n",
    "- üéØ 95-97% diagnostic accuracy on NIH malaria dataset\n",
    "- üí∞ 60-90% energy savings vs traditional training\n",
    "- üìä Publication-ready visualizations\n",
    "- üî¨ Interpretable AI with Grad-CAM\n",
    "\n",
    "---\n",
    "\n",
    "**‚öôÔ∏è Setup**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4, P100, or V100)\n",
    "\n",
    "**‚è±Ô∏è Time**: ~25-40 minutes end-to-end (with GPU)\n",
    "\n",
    "**üìä Dataset**: NIH Malaria Cell Images (27,558 images from Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_1"
   },
   "source": [
    "## üì¶ Step 1: Clone Repository and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": "# Clone the repository (or upload files manually)\n!git clone https://github.com/oluwafemidiakhoa/Malaria.git\n%cd Malaria/malaria_ast_starter\n\n# If you uploaded files manually instead, uncomment:\n# %cd malaria_ast_starter"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_2"
   },
   "source": [
    "## üîë Step 2: Setup Kaggle API\n",
    "\n",
    "**Instructions**:\n",
    "1. Go to https://www.kaggle.com/settings\n",
    "2. Scroll to \"API\" section\n",
    "3. Click \"Create New API Token\"\n",
    "4. Upload the downloaded `kaggle.json` when prompted below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_kaggle"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üìÅ Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle API configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_3"
   },
   "source": [
    "## üöÄ Step 3: Automated Setup (Downloads Dataset + Installs Dependencies)\n",
    "\n",
    "This will:\n",
    "- Download NIH malaria dataset from Kaggle (~350 MB)\n",
    "- Organize into train/val splits (80/20)\n",
    "- Install all dependencies\n",
    "- Create optimized config for your GPU\n",
    "- Mount Google Drive for saving outputs\n",
    "\n",
    "**‚è±Ô∏è Expected time: 3-5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auto_setup"
   },
   "outputs": [],
   "source": [
    "# Run automated setup\n",
    "!python colab_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_4"
   },
   "source": [
    "## üî• Step 4: Train with Adaptive Sparse Training\n",
    "\n",
    "**Default config**: 40% activation rate = 60% energy savings\n",
    "\n",
    "**Training time estimates**:\n",
    "- T4 GPU: ~25-30 minutes (30 epochs)\n",
    "- P100 GPU: ~20-25 minutes\n",
    "- V100/A100 GPU: ~15-20 minutes\n",
    "\n",
    "**What to expect**:\n",
    "- Real-time progress bars\n",
    "- Activation rate tracking\n",
    "- Energy savings percentage\n",
    "- Validation accuracy updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_ast"
   },
   "outputs": [],
   "source": [
    "# Train with AST (60% energy savings)\n",
    "!python train_ast.py --config configs/config_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "optional_configs"
   },
   "source": [
    "### üéõÔ∏è Optional: Try Different Energy Savings Levels\n",
    "\n",
    "Uncomment one of the blocks below to try different configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "max_buzz_config"
   },
   "outputs": [],
   "source": [
    "# # üöÄ MAXIMUM BUZZ: 90% energy savings (for headlines!)\n",
    "# !python -c \"\n",
    "# import yaml\n",
    "# with open('configs/config_colab.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)\n",
    "# cfg['ast_target_activation_rate'] = 0.10\n",
    "# cfg['ast_warmup_epochs'] = 5\n",
    "# with open('configs/config_max_buzz.yaml', 'w') as f:\n",
    "#     yaml.dump(cfg, f)\n",
    "# \"\n",
    "# !python train_ast.py --config configs/config_max_buzz.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "conservative_config"
   },
   "outputs": [],
   "source": [
    "# # üéØ CONSERVATIVE: 30% energy savings (minimal accuracy impact)\n",
    "# !python -c \"\n",
    "# import yaml\n",
    "# with open('configs/config_colab.yaml', 'r') as f:\n",
    "#     cfg = yaml.safe_load(f)\n",
    "# cfg['ast_target_activation_rate'] = 0.70\n",
    "# cfg['ast_warmup_epochs'] = 0\n",
    "# with open('configs/config_conservative.yaml', 'w') as f:\n",
    "#     yaml.dump(cfg, f)\n",
    "# \"\n",
    "# !python train_ast.py --config configs/config_conservative.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_5"
   },
   "source": [
    "## üìä Step 5: Generate Visualizations\n",
    "\n",
    "Creates publication-ready graphics:\n",
    "- 4-panel comprehensive analysis\n",
    "- Social media headline graphic\n",
    "- Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize"
   },
   "outputs": [],
   "source": [
    "!python visualize_ast.py --metrics checkpoints_ast/metrics_ast.jsonl --output-dir visualizations\n",
    "\n",
    "# Display the visualizations\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"\\nüìä 4-Panel Comprehensive Analysis:\")\n",
    "display(Image('visualizations/ast_results.png'))\n",
    "\n",
    "print(\"\\nüì∞ Social Media / Press Release Graphic:\")\n",
    "display(Image('visualizations/ast_headline.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_6"
   },
   "source": [
    "## üéØ Step 6: Evaluate Model Performance\n",
    "\n",
    "Generates:\n",
    "- Classification report (precision, recall, F1)\n",
    "- Confusion matrix\n",
    "- Per-class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "!python eval.py --weights checkpoints_ast/best.pt\n",
    "\n",
    "# Display confusion matrix\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "\n",
    "print(\"\\nüìä Confusion Matrix:\")\n",
    "display(Image('checkpoints/cm.png'))\n",
    "\n",
    "# Print classification report\n",
    "with open('checkpoints/report.json', 'r') as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_7"
   },
   "source": [
    "## üî¨ Step 7: Generate Grad-CAM Visualization\n",
    "\n",
    "See where the model is looking to make its decision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradcam"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Pick a random parasitized cell image\n",
    "parasitized_dir = Path('data/val/Parasitized')\n",
    "sample_image = list(parasitized_dir.glob('*.png'))[0]\n",
    "\n",
    "print(f\"üî¨ Generating Grad-CAM for: {sample_image.name}\")\n",
    "\n",
    "!python gradcam_snapshot.py \\\n",
    "    --weights checkpoints_ast/best.pt \\\n",
    "    --image {sample_image} \\\n",
    "    --out gradcam_parasitized.png\n",
    "\n",
    "print(\"\\nüì∏ Grad-CAM Visualization (Parasitized Cell):\")\n",
    "display(Image('gradcam_parasitized.png'))\n",
    "\n",
    "# Also try an uninfected cell\n",
    "uninfected_dir = Path('data/val/Uninfected')\n",
    "sample_image = list(uninfected_dir.glob('*.png'))[0]\n",
    "\n",
    "!python gradcam_snapshot.py \\\n",
    "    --weights checkpoints_ast/best.pt \\\n",
    "    --image {sample_image} \\\n",
    "    --out gradcam_uninfected.png\n",
    "\n",
    "print(\"\\nüì∏ Grad-CAM Visualization (Uninfected Cell):\")\n",
    "display(Image('gradcam_uninfected.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_8"
   },
   "source": [
    "## üíæ Step 8: Save Results to Google Drive\n",
    "\n",
    "Copy all outputs to your Drive for permanent storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_drive"
   },
   "outputs": [],
   "source": [
    "# Create project folder in Drive\n",
    "!mkdir -p /content/drive/MyDrive/malaria_ast_results\n",
    "\n",
    "# Copy checkpoints\n",
    "!cp -r checkpoints_ast /content/drive/MyDrive/malaria_ast_results/\n",
    "\n",
    "# Copy visualizations\n",
    "!cp -r visualizations /content/drive/MyDrive/malaria_ast_results/\n",
    "\n",
    "# Copy evaluation results\n",
    "!cp checkpoints/report.json /content/drive/MyDrive/malaria_ast_results/\n",
    "!cp checkpoints/cm.png /content/drive/MyDrive/malaria_ast_results/\n",
    "\n",
    "# Copy Grad-CAM samples\n",
    "!cp gradcam_*.png /content/drive/MyDrive/malaria_ast_results/\n",
    "\n",
    "print(\"‚úÖ All results saved to: /content/drive/MyDrive/malaria_ast_results/\")\n",
    "print(\"\\nüìÅ Saved files:\")\n",
    "!ls -lh /content/drive/MyDrive/malaria_ast_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_9"
   },
   "source": [
    "## üìà Step 9: View Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load metrics\n",
    "metrics = []\n",
    "with open('checkpoints_ast/metrics_ast.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        metrics.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üéâ TRAINING COMPLETE - FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best accuracy\n",
    "best_acc = df['val_acc'].max() * 100\n",
    "best_epoch = df.loc[df['val_acc'].idxmax(), 'epoch']\n",
    "print(f\"\\nüéØ Best Validation Accuracy: {best_acc:.2f}% (Epoch {best_epoch})\")\n",
    "\n",
    "# Average energy savings (excluding warmup)\n",
    "non_warmup = df[df['energy_savings'] > 0]\n",
    "if len(non_warmup) > 0:\n",
    "    avg_savings = non_warmup['energy_savings'].mean()\n",
    "    avg_activation = non_warmup['activation_rate'].mean()\n",
    "    print(f\"\\n‚ö° Energy Efficiency:\")\n",
    "    print(f\"   Average Energy Savings: {avg_savings:.1f}%\")\n",
    "    print(f\"   Average Activation Rate: {avg_activation*100:.1f}%\")\n",
    "    \n",
    "    total_samples_saved = (avg_savings / 100) * df['total_samples'].iloc[0] * len(non_warmup)\n",
    "    print(f\"   Total Samples Saved: {total_samples_saved:,.0f}\")\n",
    "\n",
    "# Final metrics\n",
    "final = df.iloc[-1]\n",
    "print(f\"\\nüìä Final Epoch ({final['epoch']}):\")\n",
    "print(f\"   Train Loss: {final['train_loss']:.4f}\")\n",
    "print(f\"   Val Accuracy: {final['val_acc']*100:.2f}%\")\n",
    "print(f\"   Activation Rate: {final['activation_rate']*100:.1f}%\")\n",
    "\n",
    "# Show metrics table\n",
    "print(\"\\nüìã Training History (last 10 epochs):\")\n",
    "display_cols = ['epoch', 'train_loss', 'val_acc', 'activation_rate', 'energy_savings']\n",
    "display(df[display_cols].tail(10).round(4))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíö SUCCESS! Your energy-efficient malaria detector is ready!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìÇ Next steps:\")\n",
    "print(\"   1. Download results from Google Drive\")\n",
    "print(\"   2. Use visualizations for presentations/papers\")\n",
    "print(\"   3. Share your results on social media!\")\n",
    "print(\"   4. Consider deploying the model (export_onnx.py)\")\n",
    "\n",
    "print(\"\\nüé§ Ready-to-use pitch:\")\n",
    "print(f'   \"I trained AI that detects malaria with {best_acc:.1f}% accuracy')\n",
    "print(f'    using {avg_savings:.0f}% less energy than traditional methods.\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_10"
   },
   "source": [
    "## üöÄ Optional: Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_onnx"
   },
   "outputs": [],
   "source": [
    "# Export to ONNX for production deployment\n",
    "!python export_onnx.py \\\n",
    "    --weights checkpoints_ast/best.pt \\\n",
    "    --precision fp16 \\\n",
    "    --out malaria_ast_detector_fp16.onnx\n",
    "\n",
    "# Copy to Drive\n",
    "!cp malaria_ast_detector_fp16.onnx /content/drive/MyDrive/malaria_ast_results/\n",
    "\n",
    "print(\"\\n‚úÖ ONNX model exported and saved to Drive!\")\n",
    "print(\"   Ready for deployment on edge devices, mobile apps, or web services\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_11"
   },
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- **CLAUDE.md**: Technical architecture deep dive\n",
    "- **README_AST.md**: Project overview and features\n",
    "- **PRESS_KIT.md**: Media resources and headlines\n",
    "- **GETTING_STARTED.md**: Setup tutorial\n",
    "\n",
    "### Headline Ideas (from Press Kit)\n",
    "\n",
    "**Tech Media**:\n",
    "- \"90% Energy Savings: New Sparse Training Method Makes Medical AI Accessible\"\n",
    "- \"How Adaptive Sparse Training is Democratizing Medical AI in Africa\"\n",
    "\n",
    "**Health Media**:\n",
    "- \"AI-Powered Malaria Detection System Designed for Clinics with Limited Power\"\n",
    "- \"Sustainable AI: New Method Reduces Carbon Footprint While Fighting Malaria\"\n",
    "\n",
    "**Academic**:\n",
    "- \"Adaptive Sparse Training Achieves 60% Energy Savings in Medical Image Classification\"\n",
    "- \"Case Study: Sundew Algorithm for Resource-Constrained Diagnostic AI\"\n",
    "\n",
    "### Dataset\n",
    "- NIH Malaria Cell Images: https://lhncbc.nlm.nih.gov/LHC-downloads/downloads.html#malaria-datasets\n",
    "- Kaggle Mirror: https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria\n",
    "\n",
    "### Citation\n",
    "```bibtex\n",
    "@software{malaria_ast_2025,\n",
    "  title={Energy-Efficient Malaria Diagnostic AI with Adaptive Sparse Training},\n",
    "  author={Your Name},\n",
    "  year={2025},\n",
    "  url={https://github.com/yourusername/malaria-ast}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ‚ù§Ô∏è for accessible, sustainable AI in global health** üåçüíö"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}