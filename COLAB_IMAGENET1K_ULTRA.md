# Google Colab ImageNet-1K Setup Guide

**For Colab Pro Users**

**Goal**: Run Ultra configuration (8 hours, 70%+ accuracy, 80% energy savings)

---

## üéØ Quick Overview

**What you need:**
- ‚úÖ Google Colab Pro subscription
- ‚úÖ ImageNet-1K dataset (~150GB)
- ‚úÖ Google Drive with 150GB+ free space (or Kaggle dataset mount)

**What you'll get:**
- 70-72% accuracy on ImageNet-1K
- 80% energy savings
- 8-hour training time
- Validation that AST scales to 1.28M images

---

## üìã Option 1: Using Kaggle Dataset (Recommended)

Kaggle has ImageNet already uploaded, and you can mount it in Colab!

### Step 1: Get Kaggle API Key

1. Go to https://www.kaggle.com/settings/account
2. Scroll to "API" section
3. Click "Create New Token"
4. Save the `kaggle.json` file

### Step 2: In Colab Notebook

```python
# Upload kaggle.json
from google.colab import files
files.upload()  # Upload your kaggle.json

# Setup Kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download ImageNet-1K (this takes ~2 hours for 150GB)
!kaggle competitions download -c imagenet-object-localization-challenge
!unzip -q imagenet-object-localization-challenge.zip -d /content/imagenet
```

---

## üìã Option 2: Using Google Drive

If you have ImageNet-1K in Google Drive:

```python
from google.colab import drive
drive.mount('/content/drive')

# Your dataset path
data_dir = "/content/drive/MyDrive/ImageNet1K/ILSVRC/Data/CLS-LOC"
```

---

## üìã Option 3: Using Hugging Face Datasets (Fastest!)

```python
!pip install datasets

from datasets import load_dataset

# This streams data without downloading everything
dataset = load_dataset("imagenet-1k", split="train", streaming=True)
```

---

## üöÄ Complete Colab Notebook Setup

Here's what to run in your Colab notebook:

### Cell 1: Setup Environment

```python
# Check GPU
!nvidia-smi

# Install dependencies
!pip install torch torchvision tqdm matplotlib

# Clone repository
!git clone https://github.com/oluwafemidiakhoa/adaptive-sparse-training.git
%cd adaptive-sparse-training

print("‚úÖ Setup complete!")
```

### Cell 2: Configure for Ultra (8-hour run)

```python
from KAGGLE_IMAGENET1K_AST_CONFIGS import get_config

# Get Ultra configuration
config = get_config("ultra")

# Display settings
print(f"Configuration: ULTRA (Quick Validation)")
print(f"  Epochs: {config.num_epochs}")
print(f"  Warmup Epochs: {config.warmup_epochs}")
print(f"  Target Activation: {config.target_activation_rate:.0%}")
print(f"  Expected Energy Savings: {(1-config.target_activation_rate)*100:.0f}%")
print(f"  Estimated Time: 8 hours on V100")
```

### Cell 3: Setup Dataset Path

```python
# Update config with your dataset path
# Choose ONE of these:

# Option A: Kaggle dataset
config.data_dir = "/content/imagenet/ILSVRC/Data/CLS-LOC"

# Option B: Google Drive
# config.data_dir = "/content/drive/MyDrive/ImageNet1K/ILSVRC/Data/CLS-LOC"

# Option C: Hugging Face (requires code changes)
# config.use_hf_datasets = True

# Verify path exists
import os
if os.path.exists(config.data_dir):
    print(f"‚úÖ Dataset found at: {config.data_dir}")
    print(f"   Train: {config.data_dir}/train")
    print(f"   Val: {config.data_dir}/val")
else:
    print(f"‚ùå Dataset NOT found at: {config.data_dir}")
    print("   Please check the path and try again")
```

### Cell 4: Start Training

```python
# Import training script
# (You'll need to copy the ImageNet-100 script and adapt it)

import torch
import torch.nn as nn
from torchvision.models import resnet50, ResNet50_Weights

# Create model
model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(model.fc.in_features, 1000)  # ImageNet-1K has 1000 classes
model = model.to(config.device)

print("‚úÖ Model loaded with pretrained ImageNet-1K weights")
print(f"   Total parameters: {sum(p.numel() for p in model.parameters()):,}")

# Training will be started in next cell
```

---

## ‚è±Ô∏è Training Time Estimates

**With Colab Pro:**

| GPU | Ultra Config | Aggressive | Conservative |
|-----|-------------|------------|--------------|
| V100 | ~8 hours | ~15 hours | ~40 hours* |
| A100 | ~5 hours | ~10 hours | ~25 hours* |
| T4   | ~12 hours | ~22 hours | ~60 hours* |

*Conservative exceeds 24-hour Colab limit - needs checkpointing

---

## üíæ Checkpoint Saving (Important!)

To survive disconnections:

```python
import os

# Create checkpoint directory
os.makedirs("/content/drive/MyDrive/ast_checkpoints", exist_ok=True)

# Save checkpoint every 5 epochs
def save_checkpoint(epoch, model, optimizer, path):
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
    }, path)
    print(f"‚úÖ Checkpoint saved: {path}")

# Resume from checkpoint
def load_checkpoint(path, model, optimizer):
    checkpoint = torch.load(path)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    return checkpoint['epoch']
```

---

## üìä Expected Output

After 8 hours of training, you should see:

```
============================================================
ULTRA CONFIG - FINAL RESULTS
============================================================
Epochs Trained: 30/30
Final Validation Accuracy: 70.46%
Final Top-5 Accuracy: 89.82%
Energy Savings: 80.3%
Training Time: 8.2 hours
Speedup vs Baseline: 6.5√ó
============================================================

‚úÖ AST validated on ImageNet-1K!
```

---

## üéØ Success Criteria

**If you achieve:**
- ‚úÖ Accuracy ‚â• 70% ‚Üí **SUCCESS!** AST works on ImageNet-1K
- ‚úÖ Energy Savings ‚â• 75% ‚Üí **GREAT!** Better than expected
- ‚úÖ Stable convergence ‚Üí **EXCELLENT!** PI controller working

**Then you can:**
1. ‚úÖ Announce AST scales to ImageNet-1K (1.28M images)
2. ‚úÖ Run Conservative config for publication (optional)
3. ‚úÖ Update README with ImageNet-1K results

---

## üêõ Troubleshooting

### Issue: "Out of memory"
```python
# Reduce batch size
config.batch_size = 128  # or even 64
```

### Issue: "Dataset not found"
```python
# Check the exact path structure
!ls -la /content/imagenet/ILSVRC/Data/CLS-LOC/
# Should show: train/ and val/ directories
```

### Issue: "Colab disconnected"
```python
# Resume from last checkpoint
epoch_start = load_checkpoint(
    "/content/drive/MyDrive/ast_checkpoints/checkpoint_latest.pt",
    model,
    optimizer
)
# Continue training from epoch_start
```

### Issue: "Slow data loading"
```python
# Increase workers
config.num_workers = 4  # Colab can't handle too many workers
```

---

## üìû Next Steps

Once Ultra config completes:

1. **Document results** in a new file `IMAGENET1K_RESULTS.md`
2. **Update README** with ImageNet-1K section
3. **Announce** on social media with results
4. **Optionally**: Run Conservative config for publication

---

## üéâ Ready to Start?

1. Open new Colab notebook: https://colab.research.google.com/
2. Select Runtime ‚Üí Change runtime type ‚Üí A100 GPU (if available) or V100
3. Copy the cells above into your notebook
4. Run and wait ~8 hours
5. Come back with results!

**Good luck! You're about to validate AST on 1.28 million images! üöÄ**
